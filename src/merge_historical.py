# AWS ì£¼ê°€ ë°ì´í„°, CNBC ë°ì´í„° merge í•˜ëŠ” ì½”ë“œ
import pandas as pd
from pathlib import Path

# ==========================================
# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì •í™•í•œ íŒŒì¼ëª… í™•ì¸ í•„ìˆ˜!)
# ==========================================
BASE_DIR = Path(__file__).resolve().parent.parent

# ê°€ê³µëœ ë‰´ìŠ¤ ë°ì´í„° (ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±í•¨)
NEWS_PATH = BASE_DIR / "src" / "out" / "processed_news_sorted.csv"

# [ì¤‘ìš”] ì‚¬ìš©ìê°€ ì¤€ë¹„í•œ ê³¼ê±° ì£¼ê°€ ë°ì´í„° íŒŒì¼
STOCK_PATH = BASE_DIR / "raw" / "stock_data" / "Amazon stock data 2006.12-2021.10.csv"

# ìµœì¢… ì €ì¥ ê²½ë¡œ
OUTPUT_PATH = BASE_DIR / "src" / "out" / "final_dataset_2006_2021.csv"

def main():
    print("ğŸ”„ ê³¼ê±° ë°ì´í„°(2006-2021) ë³‘í•© ì‘ì—… ì‹œì‘...\n")

    # -------------------------------------------------------
    # 1. ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ ë° ì¼ë³„ ì§‘ê³„
    # -------------------------------------------------------
    if not NEWS_PATH.exists():
        print(f"âŒ ë‰´ìŠ¤ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {NEWS_PATH}")
        print("   ë¨¼ì € 'process_news.py'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    print(f"ğŸ“° ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ ì¤‘... ({NEWS_PATH.name})")
    news_df = pd.read_csv(NEWS_PATH)
    
    # ë‚ ì§œ í˜•ì‹ ë³€í™˜
    news_df['date'] = pd.to_datetime(news_df['date']).dt.date

    # [í•µì‹¬] ê¸°ì‚¬ ë‹¨ìœ„ ë°ì´í„°ë¥¼ -> 'ì¼ë³„(Daily)' ë°ì´í„°ë¡œ ë³€í™˜
    # ê°™ì€ ë‚ ì§œì˜ ê¸°ì‚¬ë“¤ì„ ëª¨ì•„ì„œ ê°œìˆ˜ì™€ í‰ê·  ê°ì„±ì„ êµ¬í•¨
    daily_news = news_df.groupby('date').agg({
        'title': 'count',           # ê¸°ì‚¬ ê°œìˆ˜ (Volume)
        'sentiment': 'mean'         # ê°ì„± ì ìˆ˜ í‰ê·  (Sentiment)
    }).rename(columns={'title': 'news_count', 'sentiment': 'news_sentiment'})

    print(f"   -> ì¼ë³„ ë‰´ìŠ¤ ì§‘ê³„ ì™„ë£Œ: ì´ {len(daily_news)}ì¼ì¹˜ ë°ì´í„°")

    # -------------------------------------------------------
    # 2. ì£¼ê°€ ë°ì´í„° ë¡œë“œ
    # -------------------------------------------------------
    if not STOCK_PATH.exists():
        print(f"âŒ ì£¼ê°€ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {STOCK_PATH}")
        print(f"   ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”: {STOCK_PATH}")
        return

    print(f"ğŸ“ˆ ì£¼ê°€ ë°ì´í„° ë¡œë“œ ì¤‘... ({STOCK_PATH.name})")
    try:
        # ì²œ ë‹¨ìœ„ ì½¤ë§ˆ(,)ê°€ ìˆëŠ” ê²½ìš° ì œê±°í•˜ë©´ì„œ ë¡œë“œ
        stock_df = pd.read_csv(STOCK_PATH, thousands=',')
    except Exception as e:
        print(f"âŒ ì£¼ê°€ íŒŒì¼ ì½ê¸° ì—ëŸ¬: {e}")
        return

    # ì»¬ëŸ¼ëª… ê³µë°± ì œê±° ë° ë¬¸ìì—´ ë³€í™˜
    stock_df.columns = [str(c).strip() for c in stock_df.columns]
    print(f"   â„¹ï¸ ì›ë³¸ ì£¼ê°€ ë°ì´í„° ì»¬ëŸ¼: {list(stock_df.columns)}") # ë””ë²„ê¹…ìš© ì¶œë ¥

    # ë‚ ì§œ ì»¬ëŸ¼ ì°¾ê¸° ('Date', 'date', 'ë‚ ì§œ' ë“± ëŒ€ì‘)
    date_col = None
    for col in stock_df.columns:
        if 'date' in col.lower():
            date_col = col
            break
    
    if not date_col:
        print("âŒ ì£¼ê°€ ë°ì´í„°ì—ì„œ 'Date' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # [ìˆ˜ì •ë¨] ë‚ ì§œ ë³€í™˜ ì‹œ 'utc=True' ì˜µì…˜ ì¶”ê°€í•˜ì—¬ ì—ëŸ¬ í•´ê²°
    try:
        stock_df['date'] = pd.to_datetime(stock_df[date_col], utc=True).dt.date
    except Exception as e:
        print(f"âš ï¸ ë‚ ì§œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (utc=True ì‹œë„): {e}")
        stock_df['date'] = pd.to_datetime(stock_df[date_col], errors='coerce', utc=True).dt.date
        
    stock_df.set_index('date', inplace=True)
    
    # [ìˆ˜ì •ë¨] ê°•ë ¥í•œ ì»¬ëŸ¼ ì´ë¦„ í‘œì¤€í™” (Close/Last, ì¢…ê°€ ë“± ëª¨ë‘ Closeë¡œ í†µì¼)
    rename_map = {}
    for col in stock_df.columns:
        c_lower = col.lower()
        if 'close' in c_lower and 'adj' not in c_lower: # 'Close', 'Close/Last' ë“±
            rename_map[col] = 'Close'
        elif 'adj' in c_lower and 'close' in c_lower:   # 'Adj Close'
            rename_map[col] = 'Adj Close'
        elif 'open' in c_lower:
            rename_map[col] = 'Open'
        elif 'high' in c_lower:
            rename_map[col] = 'High'
        elif 'low' in c_lower:
            rename_map[col] = 'Low'
        elif 'vol' in c_lower:
            rename_map[col] = 'Volume'
            
    if rename_map:
        stock_df.rename(columns=rename_map, inplace=True)
        print(f"   -> ì»¬ëŸ¼ëª… í‘œì¤€í™” ê²°ê³¼: {list(stock_df.columns)}")

    # 'Close' ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ë©ˆì¶¤ (í•„ìˆ˜)
    if 'Close' not in stock_df.columns:
        print("âŒ ì˜¤ë¥˜: 'Close' (ì¢…ê°€) ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   í˜„ì¬ ì»¬ëŸ¼ ëª©ë¡ì„ í™•ì¸í•˜ê³  ì½”ë“œë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜ CSV íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        return

    # -------------------------------------------------------
    # 3. ë°ì´í„° ë³‘í•© (Left Join)
    # -------------------------------------------------------
    print("ğŸ”„ ë°ì´í„° ë³‘í•© ì¤‘...")
    # ì£¼ê°€ ë°ì´í„°(Trade Days)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¶™ì„
    merged_df = stock_df.join(daily_news, how='left')

    # -------------------------------------------------------
    # 4. ë°ì´í„° ì •ì œ (Cleaning)
    # -------------------------------------------------------
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ë‰´ìŠ¤ê°€ ì—†ëŠ” ë‚ )
    merged_df['news_count'] = merged_df['news_count'].fillna(0)
    merged_df['news_sentiment'] = merged_df['news_sentiment'].fillna(0) # 0ì€ ì¤‘ë¦½

    # ì£¼ê°€ ë°ì´í„°(Open, High, Low, Close)ê°€ ë¬¸ìì—´ì¼ ê²½ìš° ìˆ«ìë¡œ ë³€í™˜
    cols_to_numeric = ['Open', 'High', 'Low', 'Close', 'Volume']
    for col in cols_to_numeric:
        if col in merged_df.columns:
            # $ í‘œì‹œ ì œê±° ë“±
            if merged_df[col].dtype == object:
                merged_df[col] = merged_df[col].astype(str).str.replace('$', '').str.replace(',', '')
            merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')

    # ë³€ë™ì„±(Volatility) ê³„ì‚°: High - Low
    if 'High' in merged_df.columns and 'Low' in merged_df.columns:
        merged_df['volatility'] = merged_df['High'] - merged_df['Low']

    # ë“±ë½ë¥ (Daily Return) ê³„ì‚°
    if 'Close' in merged_df.columns:
        merged_df['daily_return'] = merged_df['Close'].pct_change()

    # [ë¨¸ì‹ ëŸ¬ë‹ íƒ€ê²Ÿ 1] ë‚´ì¼ ì£¼ê°€ê°€ ì˜¤ë¥¼ê¹Œ? (1: ìƒìŠ¹, 0: í•˜ë½/ë³´í•©)
    merged_df['target_up_down'] = (merged_df['Close'].shift(-1) > merged_df['Close']).astype(int)

    # [ë¨¸ì‹ ëŸ¬ë‹ íƒ€ê²Ÿ 2] ë‚´ì¼ ë³€ë™ì„±ì€ ì–¼ë§ˆì¼ê¹Œ?
    if 'volatility' in merged_df.columns:
        merged_df['target_volatility'] = merged_df['volatility'].shift(-1)

    # ë§ˆì§€ë§‰ ë‚ ì€ ë‚´ì¼ ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ ì œê±°
    merged_df.dropna(inplace=True)
    
    # ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ (ê³¼ê±° -> ë¯¸ë˜)
    merged_df.sort_index(ascending=True, inplace=True)

    # -------------------------------------------------------
    # 5. ì €ì¥
    # -------------------------------------------------------
    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    merged_df.to_csv(OUTPUT_PATH)
    
    print("\n" + "="*40)
    print("âœ… ë°ì´í„° ë³‘í•© ì™„ë£Œ! (2006-2021)")
    print(f"ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {OUTPUT_PATH}")
    print(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {merged_df.shape}")
    print("="*40)
    print(merged_df[['Close', 'news_count', 'news_sentiment', 'target_up_down']].head())

if __name__ == "__main__":
    main()