# ë°ì´í„° ë¶„ì„ ì½”ë“œ
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# ==========================================
# 0. íŒŒì¼ ê²½ë¡œ ì„¤ì • (ë°©ê¸ˆ ë§Œë“  ë°ì´í„°ì…‹ ê²½ë¡œ)
# ==========================================
BASE_DIR = Path(__file__).resolve().parent.parent
# íŒŒì¼ëª…ì´ ì •í™•í•œì§€ ê¼­ í™•ì¸í•˜ì„¸ìš”!
DATA_PATH = BASE_DIR / "dataset" / "final_dataset_2006_2021.csv"
IMG_OUT_DIR = BASE_DIR / "src" / "out" / "graphs"

# ê·¸ë˜í”„ ì €ì¥ í´ë” ìƒì„±
IMG_OUT_DIR.mkdir(parents=True, exist_ok=True)

def main():
    print("ğŸ“Š [Amazon 2006-2021] í”„ë¡œì íŠ¸ ë°ì´í„° ë¶„ì„ ì‹œì‘...\n")
    
    # 1. ë°ì´í„° ë¡œë“œ
    if not DATA_PATH.exists():
        print(f"âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {DATA_PATH}")
        return
        
    df = pd.read_csv(DATA_PATH)
    
    # ë‚ ì§œ ì²˜ë¦¬
    if 'date' in df.columns:
        df['date'] = pd.to_datetime(df['date'])
        df.set_index('date', inplace=True)
    
    # ë°ì´í„° ê±´ì „ì„± ì²´í¬
    print(f"   - ì „ì²´ ë°ì´í„° ê°œìˆ˜: {len(df)}ì¼")
    news_exists_days = df[df['news_count'] > 0].shape[0]
    print(f"   - ë‰´ìŠ¤ê°€ ìˆëŠ” ë‚ : {news_exists_days}ì¼ (ì „ì²´ì˜ {news_exists_days/len(df)*100:.1f}%)")

    # -----------------------------------------------------------
    # [ê³¼ì œ í•„ìˆ˜ 1] groupbyë¥¼ ì‚¬ìš©í•œ í†µê³„ ë¶„ì„
    # -----------------------------------------------------------
    print("\nâœ… [1/3] í†µê³„ ë¶„ì„ (Groupby) ìˆ˜í–‰ ì¤‘...")
    
    # ì—°ë„ë³„(Year) ê·¸ë£¹í™”
    df['Year'] = df.index.year
    
    # 3ê°€ì§€ ë©”ì†Œë“œ ì‚¬ìš©: sum, mean, max
    yearly_stats = df.groupby('Year').agg({
        'news_count': 'sum',          # ì—°ê°„ ì´ ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜
        'news_sentiment': 'mean',     # ì—°ê°„ í‰ê·  ë‰´ìŠ¤ ê°ì„±
        'Close': 'mean',              # ì—°ê°„ í‰ê·  ì£¼ê°€
        'volatility': 'mean'          # ì—°ê°„ í‰ê·  ë³€ë™ì„±
    })
    
    print("\n--- ì—°ë„ë³„ í†µê³„ ìš”ì•½ (ìµœê·¼ 5ë…„) ---")
    print(yearly_stats.tail())
    
    # CSVë¡œ ì €ì¥ (ë¦¬í¬íŠ¸ìš©)
    yearly_stats.to_csv(BASE_DIR / "src" / "out" / "yearly_statistics.csv")

    # -----------------------------------------------------------
    # [ê³¼ì œ í•„ìˆ˜ 2] ê·¸ë˜í”„ ê·¸ë¦¬ê¸° (2ì¢… ì´ìƒ)
    # -----------------------------------------------------------
    print("\nâœ… [2/3] ì‹œê°í™” (Visualization) ìˆ˜í–‰ ì¤‘...")
    
    sns.set(style="whitegrid")
    
    # --- ê·¸ë˜í”„ 1: ì—°ë„ë³„ ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ ë³€í™” (Bar Plot) ---
    plt.figure(figsize=(10, 6))
    sns.barplot(x=yearly_stats.index, y=yearly_stats['news_count'], color='skyblue')
    plt.title('Annual News Volume Trend (2006-2021)')
    plt.ylabel('Total News Articles')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig(IMG_OUT_DIR / "graph1_news_volume_trend.png")
    plt.close()
    
    # --- ê·¸ë˜í”„ 2: ì£¼ê°€ì™€ ê°ì„± ì ìˆ˜ì˜ ê´€ê³„ (Scatter Plot) ---
    # ë°ì´í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë¯€ë¡œ ë‰´ìŠ¤ê°€ ìˆëŠ” ë‚ ë§Œ í•„í„°ë§í•´ì„œ ê·¸ë¦¼
    plot_df = df[df['news_count'] > 0]
    
    plt.figure(figsize=(10, 6))
    # ê°ì„± ì ìˆ˜ì— ë”°ë¼ ìƒ‰ìƒ ë‹¤ë¥´ê²Œ (ì–‘ìˆ˜: ë¹¨ê°•, ìŒìˆ˜: íŒŒë‘)
    sns.scatterplot(data=plot_df, x='news_sentiment', y='daily_return', 
                    hue=plot_df['news_sentiment'] > 0, palette={True: 'red', False: 'blue'}, alpha=0.6)
    plt.title('News Sentiment vs Daily Return')
    plt.xlabel('Sentiment Score (-1 to 1)')
    plt.ylabel('Daily Return')
    plt.legend(title='Positive Sentiment')
    plt.savefig(IMG_OUT_DIR / "graph2_sentiment_vs_return.png")
    plt.close()

    # --- ê·¸ë˜í”„ 3: ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ ---
    plt.figure(figsize=(8, 6))
    corr_cols = ['Close', 'Volume', 'news_count', 'news_sentiment', 'volatility']
    sns.heatmap(df[corr_cols].corr(), annot=True, cmap='coolwarm', fmt=".2f")
    plt.title('Correlation Matrix')
    plt.savefig(IMG_OUT_DIR / "graph3_correlation.png")
    plt.close()
    
    print("   -> ê·¸ë˜í”„ 3ì¥ ì €ì¥ ì™„ë£Œ (src/out/graphs í´ë” í™•ì¸)")

    # -----------------------------------------------------------
    # [ê³¼ì œ í•„ìˆ˜ 3] ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ
    # -----------------------------------------------------------
    print("\nâœ… [3/3] ë¨¸ì‹ ëŸ¬ë‹ (Machine Learning) ìˆ˜í–‰ ì¤‘...")
    
    # 1. ë°ì´í„° ì¤€ë¹„ (ë‰´ìŠ¤ê°€ ì—†ì—ˆë˜ 2006~ì´ˆë°˜ ë°ì´í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ë…¸ì´ì¦ˆê°€ ë  ìˆ˜ ìˆìŒ)
    # ì—¬ê¸°ì„œëŠ” ì „ì²´ë¥¼ ë‹¤ ì“°ë˜, ê²°ì¸¡ì¹˜ë§Œ ì œê±°
    ml_df = df.dropna().copy()
    
    # 2. Feature(X)ì™€ Target(y)
    # ë‰´ìŠ¤ ì •ë³´ì™€ ì „ë‚ ì˜ ê±°ë˜ ë°ì´í„°ë¥¼ ë³´ê³  -> ë‚´ì¼ ì˜¤ë¥¼ì§€(1) ë‚´ë¦´ì§€(0) ì˜ˆì¸¡
    features = ['news_count', 'news_sentiment', 'volatility', 'daily_return', 'Volume']
    X = ml_df[features]
    y = ml_df['target_up_down']
    
    # 3. ë°ì´í„° ë¶„ë¦¬ (ê³¼ê±° ë°ì´í„°ë¡œ í•™ìŠµ, ë¯¸ë˜ ë°ì´í„°ë¡œ í‰ê°€)
    # shuffle=Falseë¡œ í•´ì•¼ ì‹œê³„ì—´ ìˆœì„œê°€ ìœ ì§€ë¨
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False, random_state=42)
    
    # 4. ëª¨ë¸ í•™ìŠµ (Random Forest)
    model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
    model.fit(X_train, y_train)
    
    # 5. ì˜ˆì¸¡ ë° í‰ê°€
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"\n--- [Random Forest] ëª¨ë¸ í‰ê°€ ê²°ê³¼ ---")
    print(f"í•™ìŠµ ê¸°ê°„: {X_train.index.min().date()} ~ {X_train.index.max().date()}")
    print(f"í‰ê°€ ê¸°ê°„: {X_test.index.min().date()} ~ {X_test.index.max().date()}")
    print(f"ì •í™•ë„ (Accuracy): {accuracy:.4f}")
    print("\nìƒì„¸ ë³´ê³ ì„œ:")
    print(classification_report(y_test, y_pred))
    
    # 6. ë³€ìˆ˜ ì¤‘ìš”ë„ (ì–´ë–¤ ê²Œ ì˜ˆì¸¡ì— ì¤‘ìš”í–ˆë‚˜?)
    importances = pd.Series(model.feature_importances_, index=features).sort_values(ascending=False)
    print("\në³€ìˆ˜ ì¤‘ìš”ë„ (Top Features):")
    print(importances)
    
    # ì¤‘ìš”ë„ ê·¸ë˜í”„
    plt.figure(figsize=(8, 5))
    sns.barplot(x=importances.values, y=importances.index)
    plt.title('Feature Importance')
    plt.savefig(IMG_OUT_DIR / "graph4_feature_importance.png")
    plt.close()

    print("\nğŸ‰ ëª¨ë“  ê³¼ì œ ìˆ˜í–‰ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
