# src/make_dataset.py
import pandas as pd
import numpy as np
from textblob import TextBlob
from pathlib import Path
import os

# ========================================== 
# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ì í™˜ê²½ì— ë§ì¶° ìˆ˜ì • ê°€ëŠ¥) 
# ========================================== 
BASE_DIR = Path(__file__).resolve().parent.parent # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ 
RAW_DIR = BASE_DIR / "raw" 
OUT_DIR = BASE_DIR / "src" / "out" 

# ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ íŒŒì¼ëª…ì— ë§ì¶° ê²½ë¡œ ì§€ì • 
# (ì£¼ì˜: ì‹¤ì œ íŒŒì¼ëª…ì´ cbnc.txt ì¸ì§€, cnbc_news_datase.csv ì¸ì§€ í™•ì¸ í›„ ìˆ˜ì •í•˜ì„¸ìš”) 
NEWS_FILE_PATH = RAW_DIR / "cbnc.txt" 
STOCK_FILE_PATH = RAW_DIR / "stock_data" / "Amazon stock data 2022.2-2025.2.csv" 
OUTPUT_FILE_PATH = OUT_DIR / "final_dataset_for_ml.csv" 

# ==========================================
# 2. ë‰´ìŠ¤ ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
# ==========================================
def process_news_data(file_path):
    print(f"ğŸ“° ë‰´ìŠ¤ ë°ì´í„° ë¡œë”© ì¤‘... : {file_path}")
    
    # êµ¬ë¶„ì(delimiter)ê°€ ì½¤ë§ˆ(,)ì¸ì§€ íƒ­(\t)ì¸ì§€ íŒŒì¼ í˜•íƒœì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ. ê¸°ë³¸ì€ ì½¤ë§ˆ.
    # on_bad_lines='skip': í˜•ì‹ì´ ê¹¨ì§„ ë¼ì¸ì€ ë¬´ì‹œ (Kaggle ë°ì´í„°ì…‹ì— í”í•¨)
    try:
        df = pd.read_csv(file_path, on_bad_lines='skip')
    except Exception as e:
        print(f"âŒ ë‰´ìŠ¤ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

    # ë‚ ì§œ ë³€í™˜ (ISO 8601 format: 2021-09-29T17:09:39+0000)
    # errors='coerce': ë³€í™˜ ë¶ˆê°€ëŠ¥í•œ ë‚ ì§œëŠ” NaTë¡œ ì²˜ë¦¬
    if 'published_at' in df.columns:
        df['date'] = pd.to_datetime(df['published_at'], errors='coerce', utc=True).dt.date
    elif 'date' in df.columns:
        df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.date
    else:
        print("âŒ ë‰´ìŠ¤ ë°ì´í„°ì— 'published_at' ë˜ëŠ” 'date' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # ë‚ ì§œ ì—†ëŠ” í–‰ ì œê±°
    df = df.dropna(subset=['date'])

    # -------------------------------------------------------
    # í•„í„°ë§: Amazon ê´€ë ¨ ë‰´ìŠ¤ + ê±°ì‹œ ê²½ì œ ë‰´ìŠ¤ (í”„ë¡œì íŠ¸ ë²”ìœ„ í™•ì¥)
    # -------------------------------------------------------
    keywords = [
        'Amazon', 'AWS', 'AMZN', 'Bezos',  # ì•„ë§ˆì¡´ ì§ì ‘ ê´€ë ¨
        'Tech', 'Cloud', 'Nasdaq',         # ì„¹í„° ê´€ë ¨
        'Fed', 'Inflation', 'Economy'      # ê±°ì‹œ ê²½ì œ (ì£¼ê°€ì— í° ì˜í–¥)
    ]
    
    # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ê²€ìƒ‰ì„ ìœ„í•œ ì •ê·œí‘œí˜„ì‹ ìƒì„±
    pattern = '|'.join(keywords)
    
    # ì œëª©(title)ì´ë‚˜ ì„¤ëª…(description)ì— í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê¸°ì‚¬ë§Œ ì¶”ì¶œ
    mask = df['title'].str.contains(pattern, case=False, na=False)
    if 'description' in df.columns:
        mask |= df['description'].str.contains(pattern, case=False, na=False)
    
    filtered_df = df[mask].copy()
    print(f"   - ì „ì²´ {len(df)}ê°œ ì¤‘ ê´€ë ¨ ë‰´ìŠ¤ {len(filtered_df)}ê°œ ì¶”ì¶œ ì™„ë£Œ")

    # -------------------------------------------------------
    # ê°ì„± ë¶„ì„ (Sentiment Analysis)
    # -------------------------------------------------------
    print("   - ê°ì„± ë¶„ì„ ìˆ˜í–‰ ì¤‘ (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)...")
    
    def calculate_sentiment(text):
        if not isinstance(text, str):
            return 0
        return TextBlob(text).sentiment.polarity

    # ì œëª©ê³¼ ìš”ì•½ë¬¸ì„ í•©ì³ì„œ ë¶„ì„í•˜ë©´ ë” ì •í™•í•¨
    filtered_df['full_text'] = filtered_df['title'].astype(str) + " " + filtered_df['description'].fillna("").astype(str)
    filtered_df['sentiment'] = filtered_df['full_text'].apply(calculate_sentiment)

    # -------------------------------------------------------
    # ì¼ë³„ ì§‘ê³„ (Aggregation)
    # -------------------------------------------------------
    # ê°™ì€ ë‚ ì§œì— ì—¬ëŸ¬ ê¸°ì‚¬ê°€ ìˆìœ¼ë¯€ë¡œ ë‚ ì§œë³„ë¡œ ë¬¶ìŒ
    daily_news = filtered_df.groupby('date').agg({
        'title': 'count',           # ê¸°ì‚¬ ê°œìˆ˜ (Volume)
        'sentiment': 'mean'         # í‰ê·  ê°ì„± ì ìˆ˜ (Sentiment)
    }).rename(columns={'title': 'news_count', 'sentiment': 'news_sentiment'})

    return daily_news

# ==========================================
# 3. ì£¼ê°€ ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
# ==========================================
def process_stock_data(file_path):
    print(f"ğŸ“ˆ ì£¼ê°€ ë°ì´í„° ë¡œë”© ì¤‘... : {file_path}")
    try:
        df = pd.read_csv(file_path)
    except Exception as e:
        print(f"âŒ ì£¼ê°€ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

    # ë‚ ì§œ ì»¬ëŸ¼ ì°¾ê¸° (ëŒ€ì†Œë¬¸ì ì²˜ë¦¬)
    col_map = {c: c.lower() for c in df.columns}
    date_col = None
    for c in df.columns:
        if 'date' in c.lower():
            date_col = c
            break
    
    if not date_col:
        print("âŒ ì£¼ê°€ ë°ì´í„°ì— Date ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    df['date'] = pd.to_datetime(df[date_col]).dt.date
    df.set_index('date', inplace=True)
    
    return df

# ==========================================
# 4. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ==========================================
def main():
    # 1. ë°ì´í„° ë¡œë“œ ë° ê°€ê³µ
    news_df = process_news_data(NEWS_FILE_PATH)
    stock_df = process_stock_data(STOCK_FILE_PATH)

    if news_df is None or stock_df is None:
        print("âŒ ë°ì´í„° ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return

    # 2. ë°ì´í„° ë³‘í•© (Left Join: ì£¼ê°€ ë°ì´í„° ê¸°ì¤€)
    # ì£¼ì‹ ì‹œì¥ì´ ì—´ë¦° ë‚ ì„ ê¸°ì¤€ìœ¼ë¡œ ë‰´ìŠ¤ë¥¼ ë¶™ì„
    print("ğŸ”„ ë°ì´í„° ë³‘í•© ì¤‘...")
    merged_df = stock_df.join(news_df, how='left')

    # 3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    # ë‰´ìŠ¤ê°€ ì—†ëŠ” ë‚ ì€ ê¸°ì‚¬ìˆ˜=0, ê°ì„±ì ìˆ˜=0(ì¤‘ë¦½)ìœ¼ë¡œ ì±„ì›€
    merged_df['news_count'] = merged_df['news_count'].fillna(0)
    merged_df['news_sentiment'] = merged_df['news_sentiment'].fillna(0)

    # 4. íŒŒìƒ ë³€ìˆ˜ ìƒì„± (ë¨¸ì‹ ëŸ¬ë‹ìš©)
    # ë³€ë™ì„± (ê³ ê°€ - ì €ê°€)
    if 'High' in merged_df.columns and 'Low' in merged_df.columns:
        merged_df['volatility'] = merged_df['High'] - merged_df['Low']
    
    # ì „ì¼ ëŒ€ë¹„ ë“±ë½ë¥  (Return)
    if 'Close' in merged_df.columns:
        merged_df['daily_return'] = merged_df['Close'].pct_change()

    # [ì¤‘ìš”] íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± (ë‚´ì¼ì˜ ì£¼ê°€ ë³€ë™ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´)
    # shift(-1)ì„ í•´ì„œ 'ë‹¤ìŒë‚ ì˜ ë³€ë™ì„±'ì„ í˜„ì¬ í–‰ì— ê°€ì ¸ì˜´
    merged_df['target_volatility'] = merged_df['volatility'].shift(-1)
    
    # 5. ìµœì¢… ì €ì¥
    OUT_DIR.mkdir(parents=True, exist_ok=True)
    merged_df.to_csv(OUTPUT_FILE_PATH)
    
    print("\n" + "="*40)
    print("âœ… ìµœì¢… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {OUTPUT_FILE_PATH}")
    print("="*40)
    print(merged_df[['Close', 'news_count', 'news_sentiment', 'volatility']].head(10))
    print("="*40)

if __name__ == "__main__":
    main()